\chapter{Discussion and Future Work}
\label{chap:conclusion}

This dissertation has contributed computational methods for fitting stochastic epidemic models to partially observed incidence and prevalence data. Despite the ubiquity and importance of this data setting, and the historical contributions of stochastic epidemic models to the study of disease transmission, there has remained a need for computational tools that are simple, broadly applicable, and robust. 

In Chapter \ref{chap:bda_for_fitting_sems_to_prevalence_data}, we developed an agent--based Bayesian data augmentation algorithm for fitting stochastic epidemic models to prevalence data in small to moderate size populations. This work was previously published in \cite{fintzi2017efficient}. Historically, agent--based data augmentation algorithms for fitting stochastic epidemic models have relied on reversible--jump Markov chain Monte Carlo schemes to sample subject--level disease histories. The data agnostic proposals used in these methods are inefficient and perform poorly in the absence of subject--level data, which has all but precluded their use in the analysis of epidemic count data. To our knowledge, our algorithm is the first agent--based data augmentation algorithm for tractably fitting stochastic epidemic models in the absence of subject level information. Future lines of inquiry based on the methods developed in Chapter \ref{chap:bda_for_fitting_sems_to_prevalence_data} could pursue extensions of the algorithm to other data settings, in particular to incidence data and to datasets that include both aggregate counts and incomplete subject--level data, and improvements of the computational efficiency of the algorithm.

Chapter \ref{chap:lna_for_sems} developed a computationally efficient framework based on the linear noise approximation for approximate Bayesian inference of stochastic epidemic models fit to partially observed incidence. Though the linear noise approximation has previously been used in outbreak modeling, its application has been restricted to the analysis prevalence data (or cumulative incidence data, wrongly treated as prevalence data) where the data are normally distributed. We demonstrated how, through a series of reparameterizations, the linear noise approximation could be used in combination with state of the art Markov chain Monte Carlo samplers to efficiently fit stochastic epidemic models. We demonstrated through simulations that the resulting estimates were approximately equivalent to those obtained by more faithful approximations to the Markov jump process, and were superior to estimates obtained using deterministic methods. We also presented a series of easily implemented model diagnostics that could be used to assess in--sample model fit and compare the posterior predictive distributions of different models. We used our methods to fit several models to data from the 2014--2015 outbreak of Ebola in West Africa. 

Chapter \ref{chap:lna_extensions} explored how the linear noise approximation and ordinary differential equation frameworks could be used to fit stochastic epidemic models with time--varying dynamics. We allowed for the possibility of time--heterogeneity in the dynamics by modeling the basic reproduction number of the outbreak using Gaussian Markov random fields. This was an attractive choice for computational and statistical reasons, as the sparsity of the sub--models for the time--varying dynamics and their interpretations discretized versions of continuous--time processes made them particularly compatible with the other aspects of the modeling framework. We demonstrated in a simulation that the model with time--varying dynamics was able to recover the time--varying aspects of the outbreak along with time--homogeneous parameters of the model, whereas a time--homogeneous model yielded misleading estimates. Finally, we fit a complex age--vaccination stratified model to two seasons of data from the 2009--2011 A(H1N1) influenza pandemic in Finland. Due to the complexity of the model, we fit the model using the ordinary differential equation representation of the latent epidemic process. We used our model to obtain estimates of the transmission dynamics, outbreak size, and effects of a national vaccination campaign in mitigating the severity of the pandemic. 

On a personal level, one of the great lessons I learned, or at least have tried to learn, in writing this dissertation is to be forgiving of the shortcomings in my work. I am deeply grateful to my advisors, who repeatedly reminded me to stay resilient and who gave me the confidence to persist in our work. I wish to conclude this dissertation by pointing to some applied and methodological areas of general interest that I wish I had addressed. Were I to start this dissertation over (and I cannot emphasize strongly enough that I do not wish to do so), these are the problems I would work on. 

\textit{Assimilation of data from multiple sources.}
The limited extent of partially observed epidemic count data, and particularly of incidence data, severely limits the strength of the conclusions we would like to draw from the data. In chapters \ref{chap:lna_for_sems} and \ref{chap:lna_extensions}, estimates of the outbreak size and detection processes were only weakly identifiable from incidence counts. The models presented in those chapters would be greatly improved by the assimilation of additional data; at a minimum, mortality data in the case of Ebola, and data on severe and hospitalized cases for the analysis of pandemic influenza. Questions of how to jointly model and weight different sources of data are of great practical importance \cite{deangelis2015four}. 

\textit{Assessing model fit, predictive performance, and model comparison.} The model diagnostics presented in this dissertation were useful for assessing the in--sample fit, but did not address the generalizability of the models and their adequacy for out--of--sample prediction. The computational cost to fitting our models is the main challenge involved in assessing their out--of--sample predictive ability since iteratively holding out data and refitting the model is problematic for anything but simple models fit to short time series. One potentially useful line of work is the development of methods for minimizing the number of refits, e.g., \cite{buerkner2018psis}. 

\textit{Combining mechanistic models.} One challenge in working with mechanistic compartmental models is that we are required to make choices in specifying multifaceted models, every one of which is highly consequential in determining the model's validity. Even in the case of a model with SIR dynamics, we must make decisions about how to model the hazards, the contact structure of the population, the emission distribution, and the initial state of the population, on top of which we must decide if and how to model stochasticity in the latent epidemic process. Then, if we are Bayesian, we must assign priors to all of the parameters. In light of the obvious limitations of any particular model, an area of ongoing research is in combining models to draw more robust conclusions and improve predictions \cite{ray2018prediction,reich2018forecasting,yao2017using}.
